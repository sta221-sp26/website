---
title: Final project
---

```{r include = F}
library(tidyverse)
library(knitr)
library(broom)
```

## Project milestones

[Research topics](#research-topics) due Tuesday, February 11

[Project proposal](#project-proposal) due Tuesday, February 25

[Exploratory data analysis](#eda) due Thursday, March 20

[Presentation](#presentation) + [Presentation comments](#presentation-comments) Friday, March 28 (in lab)

[Analysis draft + peer review](#draft-report-peer-review) Friday, April 11 (peer review in lab)

[Written report](#written-report) due Monday, April 28

[Project highlights] due Wednesday, April 30

[Reproducibility + organization](#reproducibility-organization) due Wednesday, April 30

[Final project survey] due Thursday, May 1

## Introduction

**TL;DR**: *Pick a data set and do a regression analysis. That is your final project.*

The goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.

Choose the data based on your group's interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.

**All analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.**

### Logistics

You will work on the project with your lab groups. The primary deliverables for the project are

1.  an in-person presentation about the exploratory data analysis and initial modeling

2.  a written, reproducible final report detailing your analysis

3.  a summary of your project highlights to share with the class

4.  a GitHub repository containing all work from the project

There are intermediate milestones and peer review assignments throughout the semester to help you work towards the primary deliverables.

## Research topics {#research-topics}

The goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing ideas at this point; you do not need to have a data set identified right now.

Develop three potential research topics. Include the following for <u>each</u> topic:

1.  A brief description of the topic
2.  A statement about your motivation for investigating this topic
3.  The potential audience(s), i.e., who might be most interested in this research?
4.  Two or three potential research questions you could analyze about this topic. *(Note: These are draft questions at this point. You will finalize the questions in the next stage of the project.)*
5.  Ideas about the type of data you might use to answer this question or potential data sets you're interested in using. (*Note: The goal is to generate ideas at this point, so it is fine if you have not identified any particular data sets at this point.)*

### Submission

Write your responses in `research-topics.qmd` in your team's project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, **Tuesday, February 11 at 11:59pm**. There is no Gradescope submission.

## Project proposal {#project-proposal}

The purpose of the project proposal is for your team to identify the data set you're interested in analyzing to investigate one of your potential research topics. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you're unsure where to find data, you can use the list of potential data sources on the [Tips + resources](https://sta221-sp25.netlify.app/project-tips) page as a starting point.

::: callout-important
You must use the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.
:::

The data set must meet the following criteria:

-   At least 500 observations

-   At least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.

    -   e.g., identifier variables such as "name", "ID number", etc. are <u>not</u> useful predictor variables.

    -   e.g., if you have multiple columns with the same information (e.g. "state abbreviation" and "state name"), then they are not unique predictors.

-   At least one variable that can be identified as a reasonable response variable.

    -   The response variable can be quantitative or categorical.

-   A mix of quantitative and categorical variables that can be used as predictors.

-   May not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.

::: callout-warning
### Types of data sets to avoid

-   Data that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.

-   Data sets in which there is no information about how the data were originally collected

-   Data sets in which there are missing or unclear definitions about the observations and/or variables
:::

**Ask a member of the teaching team if you're unsure whether your data set meets the criteria.**

The proposal will include the following sections:

### Section 1: Introduction

::: callout-tip
Reuse and iterate on the work from the Research Topics milestone.
:::

-   An introduction to the subject matter you're investigating (citing any relevant literature)

-   Statement of a well-developed research question.

-   The motivation for your research question and why it is important

-   Your team's hypotheses regarding the research question

    -   This is a narrative about what you think regarding the research question, not formal statistical hypotheses.

### Section 2: Data description

-   The source of the data set

-   A description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)

-   A description of the observations and general characteristics being measured

### Section 3: Data processing

-   Description of data processing you need to do to prepare for analysis, such as joining multiple data sets, handling missing data, etc.

-   Visualizations, summary statistics, and narrative to describe the distribution of the [**response**]{.underline} variable.

### Section 4: Analysis approach

-   a description of the potential predictor variables of interest

-   regression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)

### Data dictionary (aka code book)

Submit a data dictionary for all the variables in your data set in the `README` of the `data` folder. You do <u>not</u> need to include the data dictionary in the PDF document.

### Submission

Write your narrative and analysis for Sections 1 - 4 in the `proposal.qmd` file in your team's GitHub repo. Put the data set and the data dictionary in the `data` folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline, **Tuesday, February 25 at 11:59pm.**

### Grading

The anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.

The proposal is worth 5 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.

-   **Excellent (5 points) :** All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data, any data processing, and exploration of the response variable as described above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.

-   **Strong (3 - 4 points)**: Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.

-   **Satisfactory (2 points):** Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.

-   **Needs Improvement (1 point):** Requirements are largely unmet, and there are major elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.

## Exploratory data analysis {#eda}

::: callout-tip
Reuse and iterate on the work from the previous milestones.
:::

The purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.

Below is a brief description of the sections to include in this step:

### Introduction

This section includes an introduction to the project motivation, background, data, and research question.

### Exploratory data analysis

This section includes the following:

-   Description of the data set and key variables.

-   Exploratory data analysis of the response variable and key predictor variables. This includes visualizations, summary statistics, and narrative

    -   Univariate EDA of the response and key predictor variables.
    -   Bivariate EDA of the response and key predictor variables
    -   Potential interaction effects

### Submission

Write your draft introduction and exploratory data analysis in the `written-report.qmd` file in your team's GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline.

### Grading

The anticipated length, including all graphs, tables, narrative, etc. with code, warnings, and messages suppressed is about 4 - 6 pages (It is OK to be over this page limit at this stage in the project.)

::: callout-tip
You can save space by suppressing code, warnings, and messages by including the following in the YAML:

``` r
execute:
  echo: false
  message: false
  warning: false
```
:::

The exploratory data analysis is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above, along with incorporating the feedback from the proposal. Points will be assigned based on a holistic review of the exploratory data analysis.

-   **Excellent (9 - 10 points) :** All required elements are completed and are accurate. There is a thorough exploration of the data as described above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.

-   **Strong: (7 - 8 points):** Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some revision of the work required before team is ready for modeling.

-   **Satisfactory (5 - 6 points):** Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.

-   **Needs Improvement (4 or fewer points points):** Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.

## Presentation {#presentation}

::: callout-important
Presentations will take place in class during labs. Presentation order will be announced in advance.
:::

Your team will do an in-person presentation that summarizes and showcases the work you've done on the project thus far. Because the presentations will take place while you're still working on the project, it will also be an opportunity to receive feedback and suggestions as well as provide feedback to other teams. The presentation will focus on introducing the subject matter and research question, showcase key results from the exploratory data analysis, and discuss primary modeling strategies and/or results. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.

You can create your slides with any software you like (e.g., Keynote, PowerPoint, Google Slides, etc.). You can also use Quarto to make your slides! While we won't be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It's no different than writing other documents with Quarto, so the learning curve will not be steep!

The presentation is expected to be between 5 to 6 minutes. It may [**not exceed 6 minutes**]{.underline}, due to the limited time during lab.

**Every team member is expected to speak in the presentation.** Part of the grade will be whether every team member had a meaningful speaking role in the presentation.

### Slides

The slide deck should have no more than 6 content slides + 1 title slide to ensure you have enough time to discuss each slide. s Here is a <u>suggested</u> outline as you think through the slides; you do <u>not</u> have to use this exact format for the 6 slides.

-   Title Slide

-   Slide 1: Introduce the subject, motivation, and research question

-   Slide 2: Introduce the data set

-   Slide 3 - 4: Highlights from the EDA (be sure to include EDA for the response variable!)

-   Slide 5: Initial modeling strategies / results (if applicable)

-   Slide 6: Next steps and any questions you'd like to get feedback on

### Submission

You can submit the presentation slides in two ways:

-   Put a PDF of the slides or Quarto slides in the `presentation` folder in your team's GitHub repo.

-   Put the URL to your slides in the `README` of the `presentation` folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.

::: callout-important
Slides must be submitted by the start of your lab on the day of presentations. We will use a classroom computer for the presentations.
:::

### Grading

The presentation is worth points. It will be graded based on the following:

-   **Content:** The team told a unified story that clearly introduced the subject matter, research question, and exploration of the data.

-   **Slides:** The presentation slides were organized, included clear and informative visualizations, and were easily readable.

-   **Presentation:** The team's communication style was clear and professional. The team divided the time well and stayed within the 8 minute time limit, with each team member making a meaningful contribution to the presentation.

80% of the presentation grade will be the average of the teaching team scores and 20% will be the average of the peer scores.

## Presentation comments {#presentation-comments}

::: callout-important
Click here to see the teams you're scoring and a link to the feedback form.

This portion of the project is worth 2 points and will be assessed individually.
:::

You will provide feedback on two teams' presentations. The assigned teams and link to the feedback form will be available in advance of the presentations. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores and comments.

The grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day.

## Analysis + peer review {#draft-report-peer-review}

The purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.

### Draft report

Write the draft in the `written-report.qmd` file in your project repo.

Below is a brief description of the sections to focus on in the draft:

#### Introduction and data

This section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won't fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.

#### Methodology

This section includes a brief description of your modeling process. Explain the reasoning for the type of model you're fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.

#### Results

In this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.

This section also includes initial interpretations and conclusions drawn from the model.

#### Grading

The draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written report file in the GitHub repo by the deadline.

### Peer review

**The peer review is due on Friday, April 11 at 11:59pm**.

Critically reviewing others' work is a crucial part of the scientific process, and STA 221 is no exception. Each lab team will be assigned two other teams' projects to review. Each team should push their draft to their GitHub repo by 10 am on the day their lab's draft is due. The lab that week will be dedicated to the peer review, so your team will have time to review and provide quality feedback to two other teams.

During the peer review process, you will be provided read-only access to your partner teams' GitHub repos. Provide your review in the form of GitHub issues to your partner team's GitHub repo using the issue template provided in the repo.

#### Steps for peer review

::: callout-important
## Peer review assignments

Go to the Canvas announcement to see the teams you're peer reviewing.You'll spend about 30 minutes reviewing each project.
:::

-   When you get to lab, you should have access to the GitHub repos for the teams you're reviewing. In GitHub, search the repositories for `project`, and you should see the repos for the projects you're reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review.

-   You may choose to all work on both peer reviews or have some team members focus on a single peer review. Either way there will be one peer review grade assigned per team.

-   For each team you're reviewing:

    -   Open that team's repo, read the project draft, and browse the rest of the repo.

    -   Go to the **Issues** tab in that repo, click on **New issue**, and click on **Get started** for the Peer Review issue. Write your responses to the prompts in the issue. You will answer the following questions:

        -   Describe the goal of the project.

        -   Describe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?

        -   Consider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.

        -   Describe the statistical methods, analysis approach, and discussion of model assumptions, diagnostics, model fit.

        -   Provide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.

        -   Provide constructive feedback on the interpretations and initial conclusion. What is most effective in the presentation of the results? What additional detail can the team provide to make the results and conclusions easier for the reader to understand?

        -   What aspect of this project are you most interested in and think would be interesting to highlight in the written report?

        -   Provide constructive feedback on any issues with file and/or code organization.

        -   (Optional) Any further comments or feedback?

#### Grading

The peer review will be graded on the extent to which each comprehensively and constructively addresses the components on the peer review form. There will be one peer review grade per team.

<!-- ## Round 1 submission (optional) {#round1-submission} -->

<!-- ::: callout-important -->

<!-- The Round 1 submission is due on Sunday, December 8 at 11:59pm. Reports submitted after this date will not receive preliminary feedback. -->

<!-- ::: -->

<!-- The Round 1 submission is an opportunity to receive detailed feedback on your analysis and [Written report](#written-report) before the final submission. Therefore, to make the feedback most useful, **you must submit a complete written report to receive feedback.** You will also be notified of the grade you would receive at that point. You will have the option to keep the grade (and thus you don't need to turn in an updated report) or resubmit the written report by the final submission deadline to receive a new grade. -->

<!-- #### To submit the Round 1 submission: -->

<!-- 1.  Push the updated `written-report.qmd` and `written-report.pdf` to your GitHub repo. -->

<!-- 2.  Open an issue with the title "Round 1 Submission". You can use the template issue in the GitHub repo. Make sure I am tagged in the issue (`@matackett`), so I receive an email notification of your Round 1 submission. See [Creating an issue from a repository](https://docs.github.com/en/issues/tracking-your-work-with-issues/creating-an-issue#creating-an-issue-from-a-repository) for instructions on opening an issue. Please ask a member of the teaching team for assistance if you need help opening the issue. -->

<!-- Note that this is optional, so there is <u>no</u> grade penalty for not turning in a Round 1 submission. Due to time constraints at the end of the semester, only high-level feedback will be given for the reports submitted at the final written report deadline on December 12. -->

## Written report {#written-report}

::: callout-important
Your written report must be completed in the `written-report.qmd` file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.

Before you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.
:::

-   You will submit the PDF of your final report on GitHub.

-   The PDF you submit must match the .qmd in your GitHub repository *exactly*. The mandatory components of the report are below. You are free to add additional sections as necessary. **The report, including tables and visualizations, must be no more than 10 pages long.** There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.

-   Be selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.

-   You are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.

### Introduction and data

This section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won't fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.

#### Grading criteria

The research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.

### Methodology

This section includes a brief description of your modeling process. Explain the reasoning for the type of model you're fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.

#### Grading criteria

The analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the variables in the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.

### Results

This is where you will output and discuss the final model.

Describe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.

#### Grading criteria 

The model fit is clearly assessed, and interesting findings from the model are clearly described. The model conditions and diagnostics are thoroughly and accurately assessed for the final model, if not previously discussed in the methodology. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model's predictive power is thoroughly assessed.

### Discussion + Conclusion

In this section you'll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.

#### Grading criteria

Overall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.

### Organization + formatting

This is an assessment of the overall presentation and formatting of the written report.

#### Grading criteria 

The report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted and labeled. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.

## Project highlights

::: callout-important
Your project highlights will be posted as a reply to the "Final project highlights" thread under the **Discussions** tab on Canvas.

You are welcome to but not required to put the highlights in your project repo.
:::

The project highlights are an opportunity to share an overview of your project and final results with your peers! Choose one of the following formats to share your highlights:

#### Option 1: Structured Abstract

A structured abstract extends on a traditional abstract by separating the content into separate sections. The abstract will be about 200 - 400 words and will be split into the following sections:

1.  Project title
2.  Background (also called Objectives in some journals)
3.  Methods
4.  Results
5.  Conclusions

Below are some examples of structured abstracts. These examples are here to give you an idea of what a structured abstract looks like; you are not required (or expected) to exactly replicate any one of these abstracts. \

-   [Structured abstract example 1](https://pubs.asha.org/doi/full/10.1044/2021_JSLHR-21-00309?casa_token=H0wAWl_5ebIAAAAA%3AEOFu-_DLS_p0JGfAv7dZ1Khy3Db48h7y76Z753Gm58qneU8GpPJ8s55TkZUy-scOgw6OAb5hMF493pHx)
-   [Structured abstract example 2](https://www.demographic-research.org/authors/SubmissionGuidelinesExample1)
-   [Tips for writing abstracts](https://writing.wisc.edu/handbook/assignments/writing-an-abstract-for-your-research-paper/) (see Example Abstract 4: A Structured Abstract)

#### Option 2: Summary slides

This is a good option if you would like to include some visualizations and output along with a short narrative describing the project highlights. These slides can be organized similarly as the structured abstract (option 1) with a slide for each section:

1.  Title slide
2.  Background
3.  Methods
4.  Results
5.  Conclusions

#### Option 3: Summary video

This is a good option if you would like to record a short presentation sharing your project highlights. You may use slides following a similar structure as Option 2 or find another creative way to present your results! The video should be no longer that 3 minutes.

#### Grading criteria

The project highlights will be graded based on how clarity of the summary and neatly done abstracts, slides, or video.

## Reproducibility + organization {#reproducibility-organization}

All written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.

The GitHub repo should have the following structure:

-   `README`: Project title and team name

    -   Optional: Short project summary

-   `written-report.qmd` & `written-report.pdf`: Final written report

-   `proposal.qmd` & `proposal.pdf`: Project proposal

-   `research-topics.qmd` & `research-topics.pdf`: Proposed research questions

-   `/data`: Folder that contains the data set for the final project.

    -   `/data/README.md`: Data dictionary and source for data set

-   `project.Rproj`: File specifying the RStudio project

-   `/presentation`: Folder with the presentation slides or link to slides.

-   `.gitignore`: File that lists all files that are in the local RStudio project but not the GitHub repo

-   `/.github`: Folder for peer review issue template

-   Any other files should be neatly organized into clearly labeled folders.

Update the README of the project repo with your project title and team members' names.

Points for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the `README` should be easily readable.

## Final project survey

You will complete a short survey about the project. You will receive the survey via email.

## Peer teamwork evaluation

There will be an opportunity to provide feedback to Professor Tackett about each team member's contribution to the project. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.

## Overall grading

The grade breakdown is as follows:

| Total                          | 100 pts |
|--------------------------------|---------|
| Research topics                | 3 pts   |
| Project proposal               | 5 pts   |
| Exploratory data analysis      | 10 pts  |
| Presentation                   | 10 pts  |
| Presentation comments          | 2 pts   |
| Draft report + peer review     | 10 pts  |
| Written report                 | 40 pts  |
| Project highlights             | 15 pts  |
| Reproducibility + organization | 3 pts   |
| Project survey                 | 2 pts   |

### Grading summary 

Grading of the project will take into account the following:

-   Content - What is the quality of research and/or policy question and relevancy of data to those questions?

-   Correctness - Are statistical procedures carried out and explained correctly?

-   Writing and Presentation - What is the quality of the statistical presentation, writing, and explanations?

-   Creativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?

-   A general breakdown of scoring is as follows:

    -   90%-100%: Outstanding effort. Team understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.

    -   80%-89%: Good effort. Team understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.

    -   70%-79%: Passing effort. Team has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.

    -   60%-69%: Struggling effort. Team is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.

    -   Below 60%\*: Team is not making a sufficient effort.

## Late work policy

There is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.

**Be sure to turn in your work early to avoid any technological mishaps.**
